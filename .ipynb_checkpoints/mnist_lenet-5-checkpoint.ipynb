{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "print(tf.version.VERSION)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "gpu = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpu[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 32, 32, 1)\n",
      "(60000,)\n",
      "(10000, 32, 32, 1)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "data = keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = data.load_data()\n",
    "\n",
    "x_train = np.pad(x_train, ((0,0), (2,2), (2,2)), 'constant', constant_values=0)\n",
    "x_train = x_train / 255.\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], 32, 32, 1))\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "x_test = np.pad(x_test, ((0,0), (2,2), (2,2)), 'constant', constant_values=0)\n",
    "x_test = x_test / 255.\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], 32, 32, 1))\n",
    "x_train = x_train.astype(np.float32)\n",
    "x_test = x_test.astype(np.float32)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(32,32,1), name='hand_writing_digit')\n",
    "conv2d_1 = keras.layers.Conv2D(filters=6, kernel_size=(5,5), activation='relu', name='conv2d_1')(inputs)\n",
    "pool_1 = keras.layers.AveragePooling2D((2,2), name='pool_1')(conv2d_1)\n",
    "conv2d_2 = keras.layers.Conv2D(filters=16, kernel_size=(5,5), activation='relu', name='conv2d_2')(pool_1)\n",
    "pool_2 = keras.layers.AveragePooling2D((2,2), name='pool_2')(conv2d_2)\n",
    "flatten = keras.layers.Flatten(name='flatten')(pool_2)\n",
    "dense_1 = keras.layers.Dense(120, activation='relu', name='dense_1')(flatten)\n",
    "dense_2 = keras.layers.Dense(84, activation='relu', name='dense_2')(dense_1)\n",
    "outputs = keras.layers.Dense(10, name='outputs')(dense_2)\n",
    "\n",
    "# Multi-Layer Perceptron\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name='lenet5_mlp')\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    \n",
    "model.compile(\n",
    "    optimizer='SGD',\n",
    "    loss=loss_fn,\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"lenet5_mlp\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hand_writing_digit (InputLay [(None, 32, 32, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "pool_1 (AveragePooling2D)    (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 16)        2416      \n",
      "_________________________________________________________________\n",
      "pool_2 (AveragePooling2D)    (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               48120     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "outputs (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = 'checkpoints/parameters-{epoch:04d}.ckpt'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    verbose=1,\n",
    "    period=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 10s 167us/sample - loss: 0.7101 - accuracy: 0.7768\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 9s 145us/sample - loss: 0.2112 - accuracy: 0.9359\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 11s 178us/sample - loss: 0.1485 - accuracy: 0.9548\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 9s 150us/sample - loss: 0.1144 - accuracy: 0.9646\n",
      "Epoch 5/20\n",
      "59328/60000 [============================>.] - ETA: 0s - loss: 0.0951 - accuracy: 0.9703\n",
      "Epoch 00005: saving model to checkpoints/parameters-0005.ckpt\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.0949 - accuracy: 0.9704\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.0825 - accuracy: 0.9745\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.0707 - accuracy: 0.9782\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 0.0640 - accuracy: 0.9809\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 6s 95us/sample - loss: 0.0581 - accuracy: 0.9818\n",
      "Epoch 10/20\n",
      "59968/60000 [============================>.] - ETA: 0s - loss: 0.0537 - accuracy: 0.9833\n",
      "Epoch 00010: saving model to checkpoints/parameters-0010.ckpt\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 0.0537 - accuracy: 0.9833\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.0494 - accuracy: 0.9848\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.0458 - accuracy: 0.9859\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.0418 - accuracy: 0.9869\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.0392 - accuracy: 0.9877\n",
      "Epoch 15/20\n",
      "59712/60000 [============================>.] - ETA: 0s - loss: 0.0369 - accuracy: 0.9881\n",
      "Epoch 00015: saving model to checkpoints/parameters-0015.ckpt\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.0370 - accuracy: 0.9881\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.0347 - accuracy: 0.9892\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.0323 - accuracy: 0.9902\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.0302 - accuracy: 0.9906\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.0286 - accuracy: 0.9907\n",
      "Epoch 20/20\n",
      "59968/60000 [============================>.] - ETA: 0s - loss: 0.0267 - accuracy: 0.9915\n",
      "Epoch 00020: saving model to checkpoints/parameters-0020.ckpt\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.0267 - accuracy: 0.9916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff83b9ca6d8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "model.save_weights(checkpoint_path.format(epoch=0))\n",
    "\n",
    "model.fit(x_train, y_train, epochs=epochs, callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 - 0s - loss: 0.0447 - accuracy: 0.9863\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.044687426996655996, 0.9863]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/lukec/venv/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: models/assets\n"
     ]
    }
   ],
   "source": [
    "model_path = 'models/lenet5.h5'\n",
    "model_dir = os.path.dirname(model_path)\n",
    "model.save(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([\n",
    "    model,\n",
    "    tf.keras.layers.Softmax()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(x):\n",
    "    pred = probability_model(x)\n",
    "    indeces = np.argmax(pred, axis=1)\n",
    "    scores = np.max(pred, axis=1)\n",
    "    return list(zip(indeces, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = get_predictions(x_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ture: 7, Prediction: (7, 0.9999589)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff859698828>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 0\n",
    "print(f'Ture: {y_test[idx]}, Prediction: {pred[idx]}')\n",
    "plt.imshow(x_test[idx,:,:,0], cmap='Greys', vmin=0, vmax=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 - 0s - loss: 0.0447 - accuracy: 0.9863\n",
      "Untrained model, accuracy: 98.63%\n"
     ]
    }
   ],
   "source": [
    "# load parameters from models\n",
    "saved_model = keras.Model(inputs=inputs, outputs=outputs, name='lenet5_mlp_2')\n",
    "saved_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=loss_fn,\n",
    "    metrics=['accuracy'])\n",
    "loss, acc = saved_model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f'Untrained model, accuracy: {100*acc:5.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkpoints/parameters-0020.ckpt'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 - 0s - loss: 0.0447 - accuracy: 0.9863\n",
      "Untrained model, accuracy: 98.63%\n"
     ]
    }
   ],
   "source": [
    "saved_model.load_weights(latest)\n",
    "\n",
    "loss, acc = saved_model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f'Untrained model, accuracy: {100*acc:5.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('_CHECKPOINTABLE_OBJECT_GRAPH', []),\n",
       " ('layer_with_weights-0/bias/.ATTRIBUTES/VARIABLE_VALUE', [6]),\n",
       " ('layer_with_weights-0/kernel/.ATTRIBUTES/VARIABLE_VALUE', [5, 5, 1, 6]),\n",
       " ('layer_with_weights-1/bias/.ATTRIBUTES/VARIABLE_VALUE', [16]),\n",
       " ('layer_with_weights-1/kernel/.ATTRIBUTES/VARIABLE_VALUE', [5, 5, 6, 16]),\n",
       " ('layer_with_weights-2/bias/.ATTRIBUTES/VARIABLE_VALUE', [120]),\n",
       " ('layer_with_weights-2/kernel/.ATTRIBUTES/VARIABLE_VALUE', [400, 120]),\n",
       " ('layer_with_weights-3/bias/.ATTRIBUTES/VARIABLE_VALUE', [84]),\n",
       " ('layer_with_weights-3/kernel/.ATTRIBUTES/VARIABLE_VALUE', [120, 84]),\n",
       " ('layer_with_weights-4/bias/.ATTRIBUTES/VARIABLE_VALUE', [10]),\n",
       " ('layer_with_weights-4/kernel/.ATTRIBUTES/VARIABLE_VALUE', [84, 10]),\n",
       " ('optimizer/decay/.ATTRIBUTES/VARIABLE_VALUE', []),\n",
       " ('optimizer/iter/.ATTRIBUTES/VARIABLE_VALUE', []),\n",
       " ('optimizer/learning_rate/.ATTRIBUTES/VARIABLE_VALUE', []),\n",
       " ('optimizer/momentum/.ATTRIBUTES/VARIABLE_VALUE', [])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.list_variables(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"lenet5_mlp\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hand_writing_digit (InputLay [(None, 32, 32, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "pool_1 (AveragePooling2D)    (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 16)        2416      \n",
      "_________________________________________________________________\n",
      "pool_2 (AveragePooling2D)    (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               48120     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "outputs (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = keras.models.load_model(model_dir)\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 - 0s - loss: 0.0447 - accuracy: 0.9863\n",
      "Untrained model, accuracy: 98.63%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = new_model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f'Untrained model, accuracy: {100*acc:5.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"lenet5_encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hand_writing_digit (InputLay [(None, 32, 32, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "pool_1 (AveragePooling2D)    (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 16)        2416      \n",
      "_________________________________________________________________\n",
      "pool_2 (AveragePooling2D)    (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               48120     \n",
      "=================================================================\n",
      "Total params: 50,692\n",
      "Trainable params: 0\n",
      "Non-trainable params: 50,692\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder = keras.Model(inputs, dense_1, name='lenet5_encoder')\n",
    "\n",
    "# not allow changing weights\n",
    "for layer in encoder.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input = keras.Input(shape=(120,), name='encoded_img')\n",
    "dense_2 = keras.layers.Dense(84, activation='relu', name='dense_2')(encoded_input)\n",
    "outputs = keras.layers.Dense(10, name='outputs')(dense_2)\n",
    "\n",
    "dense_nn_model = keras.Model(encoded_input, outputs, name='dense_nn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained weights\n",
    "for trained_layer, empty_layer in zip(new_model.layers[-2:], dense_nn_model.layers[1:]):\n",
    "    empty_layer.trainable = False\n",
    "    empty_layer.set_weights(trained_layer.get_weights())\n",
    "    \n",
    "dense_nn_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=loss_fn,\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dense_nn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoded_img (InputLayer)     [(None, 120)]             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "outputs (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 11,014\n",
      "Trainable params: 0\n",
      "Non-trainable params: 11,014\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dense_nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5, 1, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[[-0.28998306,  0.11943842,  0.13029037,  0.0229655 ,\n",
       "           0.22941332, -0.0908282 ]],\n",
       "\n",
       "        [[-0.3303709 ,  0.04537072,  0.32510257, -0.11183213,\n",
       "           0.04925697,  0.03118352]],\n",
       "\n",
       "        [[-0.15095334, -0.11915299,  0.5151876 , -0.14418551,\n",
       "          -0.08762196,  0.2208617 ]],\n",
       "\n",
       "        [[ 0.20694783, -0.06171307,  0.29746717, -0.17144936,\n",
       "          -0.06285409, -0.04826252]],\n",
       "\n",
       "        [[ 0.15600035, -0.07005176, -0.0912826 , -0.13388784,\n",
       "          -0.11314193,  0.07175418]]]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(new_model.layers[1].get_weights()[0].shape)\n",
    "new_model.layers[1].get_weights()[0][:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5, 1, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[[-0.28998306,  0.11943842,  0.13029037,  0.0229655 ,\n",
       "           0.22941332, -0.0908282 ]],\n",
       "\n",
       "        [[-0.3303709 ,  0.04537072,  0.32510257, -0.11183213,\n",
       "           0.04925697,  0.03118352]],\n",
       "\n",
       "        [[-0.15095334, -0.11915299,  0.5151876 , -0.14418551,\n",
       "          -0.08762196,  0.2208617 ]],\n",
       "\n",
       "        [[ 0.20694783, -0.06171307,  0.29746717, -0.17144936,\n",
       "          -0.06285409, -0.04826252]],\n",
       "\n",
       "        [[ 0.15600035, -0.07005176, -0.0912826 , -0.13388784,\n",
       "          -0.11314193,  0.07175418]]]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weights are inherited from origional layer\n",
    "print(encoder.layers[1].get_weights()[0].shape)\n",
    "encoder.layers[1].get_weights()[0][:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 10)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = new_model.layers[len(new_model.layers)-1]\n",
    "layer.get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 120)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_test = encoder.predict(x_test)\n",
    "encoded_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 - 0s - loss: 0.0447 - accuracy: 0.9863\n"
     ]
    }
   ],
   "source": [
    "# the seperated models are able to match the single trianed model\n",
    "loss, acc = dense_nn_model.evaluate(encoded_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
